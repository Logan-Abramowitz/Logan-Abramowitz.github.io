---
layout: project
title: Predict to Get Picked
description: Prediction Models for Formula 1 Constructors
technologies: [SQL, Python, Machine Learning]
image: /assets/images/f1-coverphoto.jpg
---

Throughout the spring semester of 2025, I worked on a group project for my Practical Tools for Operations Research, Machine Learning, and Data Science class, ORIE 3120. I worked in a group of four to analyze trends and create prediction models from Formula 1 data. This was a semester-long project that went through many iterations and pivots, ultimately culminating in a fifteen-page report from over eighty hours of work.

Early in the semester, each of us performed basic data exploration on datasets of our choice and wrote recommendation memos to our teammates regarding the depth of analysis we believed could be done on our particular dataset. From these memos and a group discussion, we collectively agreed to dig deep into the F1 dataset. This was due to a variety of factors such as the scale of the records, number of tables, number of features within those tables, and relatively few null values.

Now that we had our dataset, we needed a goal to guide our research. We decided to investigate "fairness" within F1, as a governing body of F1, such as the FIA, would stand to benefit from our findings. To start our investigation, we each asked one descriptive question and searched for the answers within the dataset. I looked into the average lap times of many different circuits to understand that a driver's overall average lap time can be highly influenced by which circuits they race on. Later, I went on to normalize these findings by dividing the length of the circuits by the average lap times to get average speeds. From these initial investigations, we found that there were in fact large discrepancies between circuits in both average lap times and average lap speeds—meaning that the circuits where drivers raced would be a factor to keep in mind, as they could be a source of "unfairness."

With these findings, along with my teammates' investigations, we wrote a draft report to submit for evaluation from our professor and peers. From these evaluations, we discovered that our goal of "fairness" was very broad and difficult to define and measure. Therefore, we decided to pivot the aim of our project to aid constructors in developing strategies for their drivers. For this new goal, we chose to investigate final placement position and pit stop timing, as this information is crucial to constructors when developing strategies.

I decided to focus on the pit stop timing part of this project. Since the event of a pit stop occurring on a particular lap for a driver is either true or false, using logistic regression felt like the natural option. Before I could run a logistic regression, I compiled and cleaned the data into one large dataset with many relevant fields. I also manufactured several fields that would aid in the regression, such as: number of laps since last pit stop, average lap time over the last three laps, and more.

I then ran the regression with a train-test split of 70-30 and found that the model was accurately predicting whether or not a pit stop would occur with 97% accuracy. However, upon further investigation, I found that the model had simply predicted that every lap would not have a pit stop. Since about 3% of laps do contain a pit stop according to our data, this made sense—but it also meant that the regression was not insightful. Because of this, I pivoted to instead use a random forest classifier, as I knew that it could better classify complex, non-linear relationships than logistic regression.

At first, I was skeptical when the random forest results came back due to a low recall score but was cautiously optimistic when I saw that my manufactured feature, change in lap time, was a very impactful feature. To truly understand how useful this random forest model could be, I created a confusion matrix and graphed the results in an ROC curve. This graph had an area under the curve (AUC) of 0.91 (the closer to 1, the better), meaning that the model would rank a lap that contains a pit stop higher than a lap that does not contain a pit stop 91% of the time. Because of this, I believe that this model could assist in developing racing strategies revolving around opponents' pit stops.

After I finished this analysis, I rejoined my group to work on writing our final report. We worked very collaboratively and helped out anyone who needed it. The report ended up being about fifteen pages in total. My main contributions were Section 3 (Predicting Pit Stop Timings) and organizing the appendix. I also made sure every figure had a hyperlink that went to it for ease of reading. If you are interested, I highly recommend reading our [final report]({{ "/assets/F1_Analysis.pdf" | relative_url }}).